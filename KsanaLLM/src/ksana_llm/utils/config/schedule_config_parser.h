/* Copyright 2024 Tencent Inc.  All rights reserved.

==============================================================================*/

#pragma once

#include <string>
#include <unordered_map>
#include <vector>

#include "ksana_llm/connector/config.h"
#include "ksana_llm/utils/config/model_config_parser.h"
#include "ksana_llm/utils/device_types.h"
#include "ksana_llm/utils/logger.h"
#include "ksana_llm/utils/search_path.h"
#include "ksana_llm/utils/status.h"
#include "ksana_llm/utils/yaml_reader.h"

namespace ksana_llm {

enum PreemptMode { SWAP = 0, RECOMPUTE = 1 };

// GEMM reduction precision for cublas
enum class GemmReductionPrecision { FP32 = 0, FP16 = 1 };

enum ScheduleStrategy { CONTINUOUS_BATCHING = 0 };

enum PPMultibatchWBStrategy { NO_WB = 0, NO_DYNAMIC_WB = 1, WB_BATCH_REQ = 2, WB_BATCH_TOKEN = 3, WB_REQ_TOKEN = 4 };

// Configuration for Attention Data Parallel Group Balance strategy
struct AttentionDPGroupBalanceConfig {
  // Whether to enable ADP balance strategy
  bool enable_balance = false;
  // Maximum wait steps before timeout
  size_t max_waiting_steps = 50;
  // Maximum wait time in milliseconds before timeout
  size_t max_waiting_time_in_ms = 1000;
  // Minimum QPS threshold for waiting, when exceeded, set max_waiting_steps=0 and max_waiting_time_in_ms=0 (no
  // accumulation) Default -1 means all QPS will use accumulation
  double min_qps_for_waiting = -1.0;
};

// Configuration for reasoning mode (e.g., DeepSeek R1)
struct ReasoningConfig {
  // Token ID for the end of thinking block (e.g., "</think>")
  // -1 means reasoning mode is disabled
  int think_end_token_id = -1;

  // Check if reasoning mode is enabled
  bool IsEnabled() const { return think_end_token_id >= 0; }

  // Check if the config is empty (not configured)
  bool Empty() const { return think_end_token_id < 0; }

  // Set the think end token ID
  void SetThinkEndTokenId(int token_id) { think_end_token_id = token_id; }

  // Get the think end token ID
  int GetThinkEndTokenId() const { return think_end_token_id; }
};

struct BatchSchedulerConfig {
  // The batch schedule strategy.
  ScheduleStrategy schedule_strategy = ScheduleStrategy::CONTINUOUS_BATCHING;

  // PP Multibatch workload balance strategy
  PPMultibatchWBStrategy pp_multibatch_wb_strategy = PPMultibatchWBStrategy::NO_WB;

  // Max waiting time in millisecond.
  size_t waiting_timeout_in_ms = 600000;

  // The max queue len of waiting request.
  size_t max_waiting_queue_len = 256;

  // The max token number for one scheduler step.
  size_t max_step_token_num = 4096;  // to be removed

  // The max batch size.
  size_t max_batch_size = 8;  // to be removed

  size_t max_pp_batch_num = 1;  // to be removed

  // The max vocab size.
  size_t max_vocab_size = 32000;  // TODO(robertyuan): Use model_config.vocab_size. To be removed

  // The maximum length the generated tokens can have
  // orresponds to the length of the input prompt + max_new_tokens.
  size_t max_token_len = 2048;  // to be removed

  // The swapin block threshold.
  float swapout_block_threshold = 1.0;

  // The swapout block threshold.
  float swapin_block_threshold = 2.0;

  // The launch block threshold.
  float launch_block_threshold = 2.0;

  // The preempt mode in case of insufficient GPU blocks.
  PreemptMode preempt_mode = SWAP;

  // This parameter controls the maximum number of tokens processed in a single
  // inference round. Setting it to 256 means that during inference, each
  // processing step (or "split") will handle up to 256 tokens. If set to 0, it
  // indicates that there is no limit on the number of tokens processed, and the
  // model will attempt to process the entire input at once. Adjusting this
  // parameter can help balance inference speed and resource consumption,
  // especially when dealing with long texts.
  size_t split_fuse_token_num = 0;

  // The number of tokens per request requiring decode computation defaults to 1. When MTP or speculative decoding is
  // enabled, a single request will compute multiple tokens.
  size_t max_decode_tokens_per_req = 1;

  // The max batch size for pre-transfer operations.
  size_t max_pretransfer_batch_size = 64;

  // The number of layers to pack together for each transfer operation (chunk transfer).
  size_t transfer_layer_chunk_size = 1;

  bool enable_speculative_decoding = false;

  size_t mtp_step_num = 0;

  // The token length for Parallel Token Prediction
  size_t ptp_step_num = 0;

  // The token id for Parallel Token Prediction
  uint32_t ptp_token_id;

  bool enable_async = false;

  bool enable_xgrammar = false;

  // ADP Balance Strategy configuration
  AttentionDPGroupBalanceConfig attention_dp_lb_config;
};

struct AllocatorConfig {
  // The preallocated blocks.
  size_t blocks_num = 0;

  // The block size, in bytes.
  size_t block_size = 0;

  // The max token number of one block.
  size_t block_token_num;

  MemoryDevice device;
};

struct BlockManagerConfig {
  // The config of allocator for cpu/gpu/npu.
  AllocatorConfig host_allocator_config;
  AllocatorConfig device_allocator_config;
  bool enable_block_checksum = false;

  // The ratio of reserved device memory.
  float reserved_device_memory_ratio = 0.05;

  // The ratio of block device memory. use all left memory if less than 0.0.
  float block_device_memory_ratio = -1.0;

  // The scale fator of block host memory.
  float block_host_memory_factor = 10.0;

  // The ratio of dynamic reusable memory.
  float dynamic_reusable_memory_ratio = 1.0;
};

// For cached manager, used for auto-prefix-caching.
struct CacheManagerConfig {
  // The token number of every block, not changed after created.
  size_t block_token_num = 16;

  // The tp num, cache manager use this to allocat blocks for every token.
  size_t tensor_para_size = 2;

  // The minimum consecutive length of flexible cache instances that can be
  // queried.
  size_t min_flexible_cache_num = 0;

  // The thread number used for async swap in/out.
  size_t swap_threadpool_size = 2;

  // Whether enable prefix caching.
  bool enable_prefix_caching = false;
};

// For multiple node pipeline.
struct PipelineConfig {
  std::string master_host;
  uint16_t master_port;

  // Default for standalone mode.
  size_t world_size = 1;
  size_t node_rank = 0;

  // layer id range.
  int16_t lower_layer_idx = -1;
  int16_t upper_layer_idx = -1;

  // netxn layer id range.
  int16_t lower_nextn_layer_idx = -1;
  int16_t upper_nextn_layer_idx = -1;

  // The cache block num.
  // All pipeline nodes must be same.
  size_t device_block_num;
  size_t host_block_num;

  // The current port for data transfer.
  std::string data_host;
  uint16_t data_port;

  // The downstream data port for data transfer.
  std::string downstream_host;
  uint16_t downstream_port;

  // The nccl unique_id.
  char nccl_unique_id[128];

  DistributedCommunicationType pipeline_para_comm_type = DistributedCommunicationType::DEFAULT;

  void SetDistributeRelatedConfig() {
    const char *master_host_env = std::getenv("MASTER_HOST");
    const char *master_port_env = std::getenv("MASTER_PORT");
    const char *world_size_env = std::getenv("WORLD_SIZE");
    const char *node_rank_env = std::getenv("NODE_RANK");

    world_size = world_size_env ? std::stoi(world_size_env) : 1;
    node_rank = node_rank_env ? std::stoi(node_rank_env) : 0;
    if (world_size > 1) {
      if (!master_host_env || !master_port_env) {
        throw std::runtime_error(
            "The environment variable MASTER_HOST and MASTER_PORT must be set in distributed mode.");
      }
    }

    master_host = master_host_env ? master_host_env : "";
    master_port = master_port_env ? std::stoi(master_port_env) : 0;

    KLLM_LOG_INFO << "Initialize pipeline config, master_host:" << master_host << ", master_port:" << master_port
                  << ", world_size:" << world_size << ", node_rank:" << node_rank;
  }
};

struct ExpertParallelConfig {
  // Maser node info for expert parallelism.
  std::string expert_master_host;
  uint16_t expert_master_port;

  // Default for standalone mode.
  size_t expert_world_size = 1;
  size_t expert_para_size = 1;
  size_t expert_node_rank = 0;
  // expert_tensor_para_size = tensor_para_size / expert_para_size;
  size_t expert_tensor_para_size = 1;
  // expert_global_para_size = expert_para_size * expert_world_size;
  size_t global_expert_para_size = 1;
};

// The config of KV cache
struct KVCacheConfig {
  // Bytes occupied by a block
  size_t block_bytes;
  // Offset of key/value part within one block of a layer
  size_t k_offset;
  size_t v_offset;
};

// The config of attention backend.
struct AttnBackendConfig {
  bool enable_blocked_multi_token_forwarding_kv = false;
  bool use_flashinfer_for_decode = false;
  DataType kv_cache_dtype;    // kv_cache storage type
  size_t block_token_num{0};  // The max token number of one block.
  size_t block_size{0};       // The block size, in bytes.

  // "kv_cache.dtype" specified in the yaml config
  std::string kv_cache_dtype_str = "auto";
  // Config for each KV cache used by the model
  // Mapping from KV cache type ("attention"/"indexer") to its config
  std::unordered_map<std::string, KVCacheConfig> kv_cache_configs;

  // User preference for FlashAttention implementation selection.
  enum class FlashAttnImplChoice {
    AUTO = 0,  // Auto-detect by hardware and availability (default)
    FA3,       // FlashAttention 3
    VLLM_V26,  // vLLM FlashAttention 2.6+
    FA2_V26,   // FlashAttention 2.6+
    FA2_V25    // FlashAttention 2.5+
  };
  FlashAttnImplChoice flash_attn_impl_choice = FlashAttnImplChoice::AUTO;
};

// Cublas kernel configuration
struct CublasKernelConfig {
  // GEMM reduction precision: FP16 or FP32, default is FP32
  GemmReductionPrecision gemm_reduction_precision = GemmReductionPrecision::FP32;
};

struct ParallelismBasicConfig {
  size_t tensor_parallel_size{1};
  size_t attn_data_parallel_size{1};
  size_t attn_tensor_parallel_size{1};  // Determined by tp/dp
  size_t expert_parallel_size{1};
  size_t expert_world_size{1};
  size_t moe_tensor_para_size{1};
};

enum W4AFP8_MOE_BACKEND { Default = 0, GroupTriton = 1, TensorTriton = 2 };

// Config info used during runtime
// Some configs are determined by ModelConfig and BatchSchedulerConfig
struct RuntimeConfig {
  // Group 1: parallelism config
  ParallelismBasicConfig parallel_basic_config;

  // Group 2: execution graph config
  // For attention backend.
  AttnBackendConfig attn_backend_config;
  bool enable_full_shared_expert = false;
  bool separate_prefill_decode = false;

  bool enable_prefix_caching = false;  // Whether enable prefix caching.
  bool enable_flexible_caching = false;

  // Whether to dump eplb data.
  bool enable_dump_eplb_data = false;
  bool enable_load_eplb_weight = false;

  // Backend type of w4afp8 moe
  W4AFP8_MOE_BACKEND w4afp8_moe_backend = W4AFP8_MOE_BACKEND::Default;

  // Whether to normalize q and k before rotary position embedding in attention.
  // bool enable_qk_pre_norm_before_rotary_pos = false;

  // Schedule related. determined by schedule configs and cache related configs.
  size_t max_pp_batch_num{1};  // max number of batchs in pipeline parallel.
  int max_batch_size;
  size_t max_seq_len;         // The max token number of a sequence
  size_t max_step_token_num;  //  The max token number of step

  size_t mtp_step_num = 0;
  bool enable_speculative_decoding = false;
  bool enable_async = false;

  // TODO(robertyuan): No body set it?
  bool embed_tokens_use_cpu{false};  // Embed_tokens gather operation is processed on the CPU.

  // data type of intermediate data: input data and output data type of kernels
  DataType inter_data_type;

  bool enable_o_proj_out_of_dp = false;  // Whether to enable out-of-data-parallelism for o_proj in attention.

  bool is_profile_mode = false;  // Only used for profiling performance

  bool is_decode_only = false;  // Whether the model is used for decode only.
};

class ScheduleConfigParser {
 public:
  ScheduleConfigParser();

  // Parse environment from YAML reader.
  Status ParseScheduleConfig(YamlReader &yaml_reader, const ModelConfig &model_config);

  void Reset();

  Status UpdateModelConfig(ModelConfig &model_config);

  void UpdateMembers(const std::string &model_dir, ModelConfig &model_config);

  // Get the config of batch manager.
  Status GetBatchSchedulerConfig(BatchSchedulerConfig &batch_scheduler_config);
  void SetBatchSchedulerConfig(BatchSchedulerConfig &batch_scheduler_config);

  // Get the config of cached manager.
  Status GetCacheManagerConfig(CacheManagerConfig &cache_manager_config);

  void SetCacheManagerConfig(CacheManagerConfig &cache_manager_config);

  Status GetRuntimeConfig(RuntimeConfig &runtime_config);

  // Whether the auto-prefix-caching is enabled.
  bool IsPrefixCachingEnabled();

  size_t GetTransferLayerChunkSize();

  // Get the config of block manager.
  Status GetBlockManagerConfig(BlockManagerConfig &block_manager_config);

  // TODO(yancyliu): remove from here later.
  void SetBlockManagerConfig(const BlockManagerConfig &block_manager_config);
  Status CalculateBlockNumber();
  Status ResetPipelineBlockNumber();
  size_t GetTotalDeviceBlockNum();
  size_t GetTotalHostBlockNum();
  bool IsEnableBlockChecksum();
  std::vector<int> GetDataParaGroupDevices(int dp_id);

  void SetTensorParallelSize(size_t tensor_parallel_size) {
    runtime_config_.parallel_basic_config.tensor_parallel_size = tensor_parallel_size;
  }

  void SetAttnDataParallelSize(size_t attn_data_parallel_size) {
    runtime_config_.parallel_basic_config.attn_data_parallel_size = attn_data_parallel_size;
  }

  void SetExpertParallelSize(size_t expert_parallel_size) {
    runtime_config_.parallel_basic_config.expert_parallel_size = expert_parallel_size;
  }

  size_t GetMaxBatchSize() const { return batch_scheduler_config_.max_batch_size; }

  // Modify reserved_device_memory_ratio
  void SetReservedDeviceRatio(float reserved_device_memory_ratio);

  // Set and get multiple node pipeline config.
  void SetPipelineConfig(const PipelineConfig &pipeline_config) { pipeline_config_ = pipeline_config; }

  Status GetPipelineConfig(PipelineConfig &pipeline_config) const {
    pipeline_config = pipeline_config_;
    return Status();
  }

  void GetAttnBackendConfig(AttnBackendConfig &attn_backend_config) {
    attn_backend_config = runtime_config_.attn_backend_config;
  }

  void GetCublasKernelConfig(CublasKernelConfig &cublas_kernel_config) const {
    cublas_kernel_config = cublas_kernel_config_;
  }

  void SetAttnBackendConfig(const AttnBackendConfig &attn_backend_config) {
    runtime_config_.attn_backend_config = attn_backend_config;
  }

  Status GetExpertParallelConfig(ExpertParallelConfig &expert_parallel_config) const {
    expert_parallel_config = expert_parallel_config_;
    return Status();
  }

  void SetExpertParallelConfig(const ExpertParallelConfig &expert_parallel_config) {
    expert_parallel_config_ = expert_parallel_config;
  }

  Status GetConnectorConfigs(ConnectorConfig &connector_config) const {
    // 检查connector_config_是否已初始化 - group_role
    if (connector_config_.group_role == GroupRole::NONE || connector_config_.router_addr.empty()) {
      return Status(RET_CONFIG_NOT_FOUND, "Connector config is not initialized.");
    }
    connector_config = connector_config_;
    return Status();
  }

  void SetConnectorConfigs(const ConnectorConfig &connector_config) {
    connector_config_ = connector_config;
    return;
  }

  // Get and set reasoning config
  Status GetReasoningConfig(ReasoningConfig &reasoning_config) const {
    reasoning_config = reasoning_config_;
    return Status();
  }

  void SetReasoningConfig(const ReasoningConfig &reasoning_config) { reasoning_config_ = reasoning_config; }

  // Init disaggregating prefill and decode connector config
  void InitConnectorConfig(YamlReader &yaml_reader);

  // Calculate block size via model configs.
  Status InitializeBlockManagerConfig(const ModelConfig &model_config);

  // Init Expert-Parallel Config from env.
  void InitializeExpertParallelConfig();

  // Init KV cache configs for all attention modules
  void InitializeKVCacheConfigs(const ModelConfig &model_config, const PipelineConfig &pipeline_config);

 private:
  // The config of batch schedule.
  BatchSchedulerConfig batch_scheduler_config_;

  // The config used by cache manager.
  CacheManagerConfig cache_manager_config_;

  // The config of block manager.
  BlockManagerConfig block_manager_config_;

  RuntimeConfig runtime_config_;

  // TODO(robertyuan): This two configs will be set by data channel, fix them later
  // For distributed multiple node pipeline.
  PipelineConfig pipeline_config_;
  // For expert parallel.
  ExpertParallelConfig expert_parallel_config_;

  // Store parsed connector configurations
  ConnectorConfig connector_config_;

  // Store reasoning configuration
  ReasoningConfig reasoning_config_;

  // Cublas kernel config
  CublasKernelConfig cublas_kernel_config_;
};

}  // namespace ksana_llm
